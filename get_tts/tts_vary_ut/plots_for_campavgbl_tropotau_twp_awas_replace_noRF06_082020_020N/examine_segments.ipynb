{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the TTS of various segments \n",
    "# date created: 3/3/2020\n",
    "# author: sofia chelpon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ --------------- PREP WORKSPACE --------------- ###########\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import xarray as xr \n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "%config inlinebackend.figure_format='retina'\n",
    "\n",
    "# import my TTS module, need to add path to folder\n",
    "import sys\n",
    "sys.path.insert(1, '/Volumes/scdrive2/TTS_2020/base_tts_code/')\n",
    "import tts_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Volumes/scdrive2/TTS_2020/get_tts/tts_vary_ut/MD2_outputs/twp_awas_replace_082020_020N/utbl_allseg_campavgbl_tropotau_twp_awas_replace.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-ae77a4014751>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m############ --------------- LOAD SEGMENT DATA --------------- ###########\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mutbl_allseg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Volumes/scdrive2/TTS_2020/get_tts/tts_vary_ut/MD2_outputs/twp_awas_replace_082020_020N/utbl_allseg_campavgbl_tropotau_twp_awas_replace.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmustar_allseg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Volumes/scdrive2/TTS_2020/get_tts/tts_vary_ut/MD2_outputs/twp_awas_replace_082020_020N/mustar_allseg_campavgbl_tropotau_twp_awas_replace.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtau_allseg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Volumes/scdrive2/TTS_2020/get_tts/tts_vary_ut/MD2_outputs/twp_awas_replace_082020_020N/tau_allseg_campavgbl_tropotau_twp_awas_replace.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mt_allseg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Volumes/scdrive2/TTS_2020/get_tts/tts_vary_ut/MD2_outputs/twp_awas_replace_082020_020N/t_allseg_campavgbl_tropotau_twp_awas_replace.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcompression\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"infer\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mcompression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;31m# 1) try standard library Pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Volumes/scdrive2/TTS_2020/get_tts/tts_vary_ut/MD2_outputs/twp_awas_replace_082020_020N/utbl_allseg_campavgbl_tropotau_twp_awas_replace.pkl'"
     ]
    }
   ],
   "source": [
    "############ --------------- LOAD SEGMENT DATA --------------- ###########\n",
    "utbl_allseg = pd.read_pickle('/Volumes/scdrive2/TTS_2020/get_tts/tts_vary_ut/MD2_outputs/twp_awas_replace_082020_020N/utbl_allseg_campavgbl_tropotau_twp_awas_replace.pkl')\n",
    "mustar_allseg = pd.read_pickle('/Volumes/scdrive2/TTS_2020/get_tts/tts_vary_ut/MD2_outputs/twp_awas_replace_082020_020N/mustar_allseg_campavgbl_tropotau_twp_awas_replace.pkl')\n",
    "tau_allseg = pd.read_pickle('/Volumes/scdrive2/TTS_2020/get_tts/tts_vary_ut/MD2_outputs/twp_awas_replace_082020_020N/tau_allseg_campavgbl_tropotau_twp_awas_replace.pkl')\n",
    "t_allseg = pd.read_pickle('/Volumes/scdrive2/TTS_2020/get_tts/tts_vary_ut/MD2_outputs/twp_awas_replace_082020_020N/t_allseg_campavgbl_tropotau_twp_awas_replace.pkl')\n",
    "gf_allseg = pd.read_pickle('/Volumes/scdrive2/TTS_2020/get_tts/tts_vary_ut/MD2_outputs/twp_awas_replace_082020_020N/gf_allseg_campavgbl_tropotau_twp_awas_replace.pkl')\n",
    "seg_info = pd.read_pickle('/Volumes/scdrive2/TTS_2020/get_tts/tts_vary_ut/MD2_outputs/twp_awas_replace_082020_020N/segment_info_campavgbl_tropotau_twp_awas_replace.pkl')\n",
    "trcnames_allseg = pd.read_pickle(\"/Volumes/scdrive2/TTS_2020/get_tts/tts_vary_ut/MD2_outputs/twp_awas_replace_082020_020N/trcnames_allseg.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ --------------- FILTER BY R^2 VALUES --------------- ###########\n",
    "high_r2_idx = np.ndarray.flatten(np.argwhere(seg_info['r squared'].values >= 0.65))\n",
    "\n",
    "seg_info_screened = seg_info.iloc[high_r2_idx]\n",
    "\n",
    "# screen vars \n",
    "mustar_allseg_screened = mustar_allseg[high_r2_idx]\n",
    "utbl_allseg_screened = utbl_allseg[high_r2_idx]\n",
    "tau_allseg_screened = tau_allseg[high_r2_idx]\n",
    "trcnames_allseg_screened = trcnames_allseg[high_r2_idx]\n",
    "\n",
    "gf_allseg_screened = gf_allseg[high_r2_idx]\n",
    "t_allseg_screened = t_allseg[high_r2_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ --------------- FIND MIN/MAX CURVES --------------- ###########\n",
    "min_mode_loc = np.argmin(seg_info_screened['mode age']) \n",
    "max_mode_loc = np.argmax(seg_info_screened['mode age']) \n",
    "\n",
    "min_mean_age = np.min(seg_info_screened['mean age']) \n",
    "max_mean_age = np.max(seg_info_screened['mean age']) \n",
    "print(min_mean_age, max_mean_age)\n",
    "\n",
    "min_mode_age = np.min(seg_info_screened['mode age']) \n",
    "max_mode_age = np.max(seg_info_screened['mode age']) \n",
    "print(min_mode_age, max_mode_age)\n",
    "\n",
    "# utbl  \n",
    "min_utbl = utbl_allseg_screened[min_mode_loc].values\n",
    "max_utbl = utbl_allseg_screened[max_mode_loc].values\n",
    "\n",
    "min_r2 = np.min(seg_info_screened['r squared']) \n",
    "max_r2 = np.max(seg_info_screened['r squared']) \n",
    "\n",
    "min_mustar = mustar_allseg_screened[min_mode_loc].values\n",
    "max_mustar = mustar_allseg_screened[max_mode_loc].values\n",
    "\n",
    "min_tau = tau_allseg_screened[min_mode_loc].values\n",
    "max_tau = tau_allseg_screened[max_mode_loc].values\n",
    "\n",
    "min_gf = gf_allseg_screened[min_mode_loc].values\n",
    "max_gf = gf_allseg_screened[max_mode_loc].values\n",
    "\n",
    "min_t = t_allseg_screened[min_mode_loc].values\n",
    "max_t = t_allseg_screened[max_mode_loc].values\n",
    "\n",
    "print(seg_info_screened['mode age'].mean())\n",
    "print(seg_info_screened['mean age'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the top 10, bottom 10 TTS sorted my mode \n",
    "ascend_mode = seg_info_screened.sort_values('mode age')\n",
    "short10 = ascend_mode[:10]\n",
    "long10 = ascend_mode[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get positions \n",
    "pos = pd.read_pickle('/Volumes/scdrive2/TTS_2020/get_tts/tts_vary_ut/data_prep/awas_positions.pkl')\n",
    "pos = pos.drop('Notes', axis = 0).drop('Intrument', axis = 0)\n",
    "pos_time = pos.iloc[0]\n",
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add lat/lon to the top and bottom 10 dataframes \n",
    "# create columns \n",
    "fill = np.empty(10)\n",
    "fill[:] = np.nan\n",
    "\n",
    "short10['GGALT'] = fill \n",
    "short10['GGLAT'] = fill \n",
    "short10['GGLON'] = fill \n",
    "\n",
    "# loop through every segment, match the time to the position and add it \n",
    "for idx in (np.arange(0, len(short10))):\n",
    "    seg = short10.iloc[idx]\n",
    "    time = seg.Time_UTC\n",
    "    where = np.argwhere(pos_time.values == time)\n",
    "    info = pos.iloc[:,[np.ndarray.item(where)]]\n",
    "    short10['GGALT'].iloc[idx] = np.ndarray.item(info.iloc[2].values)\n",
    "    short10['GGLAT'].iloc[idx] = np.ndarray.item(info.iloc[3].values)\n",
    "    short10['GGLON'].iloc[idx] = np.ndarray.item(info.iloc[4].values)\n",
    "    \n",
    "short10 = short10.reset_index()\n",
    "short10 = short10.drop(short10.columns[0], axis=1)\n",
    "short10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add lat/lon to the top and bottom 10 dataframes \n",
    "# create columns \n",
    "long10['GGALT'] = fill \n",
    "long10['GGLAT'] = fill \n",
    "long10['GGLON'] = fill \n",
    "\n",
    "# loop through every segment, match the time to the position and add it \n",
    "for idx in (np.arange(0, len(long10))):\n",
    "    seg = long10.iloc[idx]\n",
    "    time = seg.Time_UTC\n",
    "    where = np.argwhere(pos_time.values == time)\n",
    "    info = pos.iloc[:,[np.ndarray.item(where)]]\n",
    "    long10['GGALT'].iloc[idx] = np.ndarray.item(info.iloc[2].values)\n",
    "    long10['GGLAT'].iloc[idx] = np.ndarray.item(info.iloc[3].values)\n",
    "    long10['GGLON'].iloc[idx] = np.ndarray.item(info.iloc[4].values)\n",
    "    \n",
    "long10 = long10.reset_index()\n",
    "long10 = long10.drop(long10.columns[0], axis=1)\n",
    "long10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot prep \n",
    "mypath = '/Volumes/scdrive2/TTS_2020/contrast_readin/toga_lodhalf/toga_trace_gases_twp.nc'\n",
    "toga_trc = xr.open_dataset(mypath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = [10, 10])\n",
    "ax.scatter(long10.GGLON, long10.GGLAT, color = 'b', alpha = 0)\n",
    "ax.scatter(short10.GGLON, short10.GGLAT, color = 'r', alpha = 0)\n",
    "for i in np.arange(0, len(long10)):\n",
    "    plt.text(long10.GGLON[i], long10.GGLAT[i], str(i), fontsize = 15, color = 'b')\n",
    "    plt.text(short10.GGLON[i], short10.GGLAT[i], str(i), fontsize = 15, color = 'r')\n",
    "\n",
    "ax.grid(which = 'major')\n",
    "ax.set_title('Locations of Longest and Shortest Mode UT Segments', fontsize = 20)\n",
    "ax.set_xlabel('Longitude', fontsize = 20)\n",
    "ax.set_ylabel('Latitude', fontsize = 20)\n",
    "plt.xticks(fontsize = 15)\n",
    "plt.yticks(fontsize = 15)\n",
    "\n",
    "# landmarks\n",
    "# guam \n",
    "plt.scatter(144.7, 13.4, s = 70, marker = 'x', color = 'k')\n",
    "plt.text(145, 14, 'Guam', fontsize = 14)\n",
    "# chuuk \n",
    "plt.scatter(151.7, 7.4, s = 70, marker = 'x', color = 'k')\n",
    "plt.text(152, 7.4, 'Chuuk', fontsize = 14)\n",
    "# palau \n",
    "plt.scatter(134.6, 7.5, s = 70, marker = 'x', color = 'k')\n",
    "plt.text(135, 7.6, 'Palau', fontsize = 14)\n",
    "\n",
    "# \n",
    "plt.plot(toga_trc.GGLON, toga_trc.GGLAT, color = 'k', alpha = 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
